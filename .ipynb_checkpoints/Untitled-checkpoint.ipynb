{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class NeuralNetwork(object):\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights_input_to_hidden = np.random.normal(0.0, self.input_nodes**-0.5,\n",
    "                                       (self.input_nodes, self.hidden_nodes))\n",
    "\n",
    "        self.weights_hidden_to_output = np.random.normal(0.0, self.hidden_nodes**-0.5,\n",
    "                                       (self.hidden_nodes, self.output_nodes))\n",
    "        self.lr = learning_rate\n",
    "\n",
    "        #### TODO: Set self.activation_function to your implemented sigmoid function ####\n",
    "        #\n",
    "        # Note: in Python, you can define a function with a lambda expression,\n",
    "        # as shown below.\n",
    "        self.activation_function = lambda x : 1 / float(1 + np.exp(-x))  # Replace 0 with your sigmoid calculation.\n",
    "\n",
    "        ### If the lambda code above is not something you're familiar with,\n",
    "        # You can uncomment out the following three lines and put your\n",
    "        # implementation there instead.\n",
    "        #\n",
    "        #def sigmoid(x):\n",
    "        #    return 0  # Replace 0 with your sigmoid calculation here\n",
    "        #self.activation_function = sigmoid\n",
    "\n",
    "\n",
    "    def train(self, features, targets):\n",
    "        ''' Train the network on batch of features and targets.\n",
    "\n",
    "            Arguments\n",
    "            ---------\n",
    "\n",
    "            features: 2D array, each row is one data record, each column is a feature\n",
    "            targets: 1D array of target values\n",
    "\n",
    "        '''\n",
    "        n_records = features.shape[0]\n",
    "        delta_weights_i_h = np.zeros(self.weights_input_to_hidden.shape)\n",
    "        delta_weights_h_o = np.zeros(self.weights_hidden_to_output.shape)\n",
    "        for X, y in zip(features, targets):\n",
    "\n",
    "            final_outputs, hidden_outputs = self.forward_pass_train(X)  # Implement the forward pass function below\n",
    "            # Implement the backproagation function below\n",
    "            delta_weights_i_h, delta_weights_h_o = self.backpropagation(final_outputs, hidden_outputs, X, y,\n",
    "                                                                        delta_weights_i_h, delta_weights_h_o)\n",
    "        self.update_weights(delta_weights_i_h, delta_weights_h_o, n_records)\n",
    "\n",
    "\n",
    "    def forward_pass_train(self, X):\n",
    "        ''' Implement forward pass here\n",
    "\n",
    "            Arguments\n",
    "            ---------\n",
    "            X: features batch\n",
    "\n",
    "        '''\n",
    "        #### Implement the forward pass here ####\n",
    "        ### Forward pass ###\n",
    "        # TODO: Hidden layer - Replace these values with your calculations.\n",
    "        hidden_inputs = np.dot(X, self.weights_input_to_hidden) # signals into hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs) # signals from hidden layer\n",
    "\n",
    "        # TODO: Output layer - Replace these values with your calculations.\n",
    "        final_inputs = np.dot(hidden_outputs, self.weights_hidden_to_output) # signals into final output layer\n",
    "        final_outputs = final_inputs # signals from final output layer\n",
    "\n",
    "        return final_outputs, hidden_outputs\n",
    "\n",
    "    def backpropagation(self, final_outputs, hidden_outputs, X, y, delta_weights_i_h, delta_weights_h_o):\n",
    "        ''' Implement backpropagation\n",
    "\n",
    "            Arguments\n",
    "            ---------\n",
    "            final_outputs: output from forward pass\n",
    "            y: target (i.e. label) batch\n",
    "            delta_weights_i_h: change in weights from input to hidden layers\n",
    "            delta_weights_h_o: change in weights from hidden to output layers\n",
    "\n",
    "        '''\n",
    "        #### Implement the backward pass here ####\n",
    "        ### Backward pass ###\n",
    "\n",
    "        # TODO: Output error - Replace this value with your calculations.\n",
    "        error =  y - final_outputs# Output layer error is the difference between desired target and actual output.\n",
    "\n",
    "\n",
    "        # TODO: Backpropagated error terms - Replace these values with your calculations.\n",
    "        output_error_term = error * final_outputs * (1 - final_outputs)\n",
    "\n",
    "        # TODO: Calculate the hidden layer's contribution to the error\n",
    "        hidden_error = np.dot(self.weights_hidden_to_output, output_error_term)\n",
    "\n",
    "        hidden_error_term = hidden_error * hidden_outputs * (1 - hidden_outputs)\n",
    "\n",
    "        # Weight step (input to hidden)\n",
    "        delta_weights_i_h += hidden_error_term * X[:, None]\n",
    "        # Weight step (hidden to output)\n",
    "        delta_weights_h_o += output_error_term * hidden_outputs[:, None]\n",
    "        return delta_weights_i_h, delta_weights_h_o\n",
    "\n",
    "    def update_weights(self, delta_weights_i_h, delta_weights_h_o, n_records):\n",
    "        ''' Update weights on gradient descent step\n",
    "\n",
    "            Arguments\n",
    "            ---------\n",
    "            delta_weights_i_h: change in weights from input to hidden layers\n",
    "            delta_weights_h_o: change in weights from hidden to output layers\n",
    "            n_records: number of records\n",
    "\n",
    "        '''\n",
    "        self.weights_hidden_to_output += self.lr * (delta_weights_h_o / n_records) # update hidden-to-output weights with gradient descent step\n",
    "        self.weights_input_to_hidden += self.lr * (delta_weights_i_h / n_records) # update input-to-hidden weights with gradient descent step\n",
    "\n",
    "    def run(self, features):\n",
    "        ''' Run a forward pass through the network with input features\n",
    "\n",
    "            Arguments\n",
    "            ---------\n",
    "            features: 1D array of feature values\n",
    "        '''\n",
    "\n",
    "        #### Implement the forward pass here ####\n",
    "        # TODO: Hidden layer - replace these values with the appropriate calculations.\n",
    "        hidden_inputs =  self.forward_pass_train(features)# signals into hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs) # signals from hidden layer\n",
    "\n",
    "        # TODO: Output layer - Replace these values with the appropriate calculations.\n",
    "        final_inputs = np.dot(hidden_outputs, self.weights_hidden_to_output) # signals into final output layer\n",
    "        final_outputs = final_inputs # signals from final output layer\n",
    "\n",
    "        return final_outputs\n",
    "\n",
    "\n",
    "#########################################################\n",
    "# Set your hyperparameters here\n",
    "##########################################################\n",
    "iterations = 100\n",
    "learning_rate = 0.1\n",
    "hidden_nodes = 2\n",
    "output_nodes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.array([[0.5, -0.2, 0.1]])\n",
    "targets = np.array([[0.4]])\n",
    "weights_input_to_hidden = np.array([[0.1, -0.2],\n",
    "                       [0.4, 0.5],\n",
    "                       [-0.3, 0.2]])\n",
    "weights_hidden_to_output = np.array([[0.3],\n",
    "                       [-0.1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass_train(X):\n",
    "        ''' Implement forward pass here\n",
    "\n",
    "            Arguments\n",
    "            ---------\n",
    "            X: features batch\n",
    "\n",
    "        '''\n",
    "        #### Implement the forward pass here ####\n",
    "        ### Forward pass ###\n",
    "        activation_function = lambda x : 1 / (1 + np.exp(-x))\n",
    "        # TODO: Hidden layer - Replace these values with your calculations.\n",
    "        hidden_inputs = np.dot(X, weights_input_to_hidden) # signals into hidden layer\n",
    "        #print(hidden_inputs)\n",
    "        hidden_outputs = activation_function(hidden_inputs) # signals from hidden layer\n",
    "        #print(hidden_outputs)\n",
    "\n",
    "        # TODO: Output layer - Replace these values with your calculations.\n",
    "        final_inputs = np.dot(hidden_outputs, weights_hidden_to_output) # signals into final output layer\n",
    "        #print(final_inputs)\n",
    "        final_outputs = final_inputs # signals from final output layer\n",
    "\n",
    "        return final_outputs, hidden_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(final_outputs, hidden_outputs, X, y, delta_weights_i_h, delta_weights_h_o):\n",
    "        ''' Implement backpropagation\n",
    "\n",
    "            Arguments\n",
    "            ---------\n",
    "            final_outputs: output from forward pass\n",
    "            y: target (i.e. label) batch\n",
    "            delta_weights_i_h: change in weights from input to hidden layers\n",
    "            delta_weights_h_o: change in weights from hidden to output layers\n",
    "\n",
    "        '''\n",
    "        #### Implement the backward pass here ####\n",
    "        ### Backward pass ###\n",
    "\n",
    "        # TODO: Output error - Replace this value with your calculations.\n",
    "        error =  y - final_outputs # Output layer error is the difference between desired target and actual output.\n",
    "        #print(y, final_outputs, error)\n",
    "\n",
    "        # TODO: Backpropagated error terms - Replace these values with your calculations.\n",
    "        output_error_term = error * final_outputs * (1 - final_outputs)\n",
    "        #print(output_error_term)\n",
    "\n",
    "        # TODO: Calculate the hidden layer's contribution to the error\n",
    "        hidden_error = np.dot(weights_hidden_to_output, output_error_term)\n",
    "        print(hidden_error)\n",
    "\n",
    "        hidden_error_term = hidden_error * hidden_outputs * (1 - hidden_outputs)\n",
    "        print(hidden_error_term)\n",
    "        # Weight step (input to hidden)\n",
    "        delta_weights_i_h += hidden_error_term * X[:, None]\n",
    "        # Weight step (hidden to output)\n",
    "        delta_weights_h_o += output_error_term * hidden_outputs[:, None]\n",
    "        return delta_weights_i_h, delta_weights_h_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'int' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-8a3e6f8d5502>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbackpropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;36m0.09998924\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;36m0.4850045\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.45512111\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_input_to_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_hidden_to_output\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-67-e068a388e14a>\u001b[0m in \u001b[0;36mbackpropagation\u001b[0;34m(final_outputs, hidden_outputs, X, y, delta_weights_i_h, delta_weights_h_o)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# TODO: Backpropagated error terms - Replace these values with your calculations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutput_error_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfinal_outputs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfinal_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;31m#print(output_error_term)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'int' and 'list'"
     ]
    }
   ],
   "source": [
    "backpropagation([ 0.09998924],[ 0.4850045, 0.45512111], inputs, targets, weights_input_to_hidden, weights_hidden_to_output )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(features, targets):\n",
    "        ''' Train the network on batch of features and targets.\n",
    "\n",
    "            Arguments\n",
    "            ---------\n",
    "\n",
    "            features: 2D array, each row is one data record, each column is a feature\n",
    "            targets: 1D array of target values\n",
    "\n",
    "        '''\n",
    "        n_records = features.shape[0]\n",
    "        weights_input_to_hidden = np.array([[0.1, -0.2],\n",
    "                       [0.4, 0.5],\n",
    "                       [-0.3, 0.2]])\n",
    "        weights_hidden_to_output = np.array([[0.3],\n",
    "                       [-0.1]])\n",
    "        delta_weights_i_h = np.zeros((3,2))\n",
    "        delta_weights_h_o = np.zeros((2,1))\n",
    "        for X, y in zip(features, targets):\n",
    "\n",
    "            final_outputs, hidden_outputs = forward_pass_train(X)  # Implement the forward pass function below\n",
    "            # Implement the backproagation function below\n",
    "            print(final_outputs, hidden_outputs)\n",
    "            delta_weights_i_h, delta_weights_h_o = backpropagation(final_outputs, hidden_outputs, X, y,\n",
    "                                                                        delta_weights_i_h, delta_weights_h_o)\n",
    "        weights_hidden_to_output += 0.5 * (delta_weights_h_o / n_records)\n",
    "        weights_input_to_hidden += 0.5 * (delta_weights_i_h / n_records) # update input-to\n",
    "        print(weights_hidden_to_output)\n",
    "        print(weights_input_to_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.09998924] [ 0.4850045   0.45512111]\n",
      "[ 0.00809952 -0.00269984]\n",
      "[ 0.00202306 -0.00066952]\n",
      "[[ 0.30654717]\n",
      " [-0.09385623]]\n",
      "[[ 0.10050576 -0.20016738]\n",
      " [ 0.39979769  0.50006695]\n",
      " [-0.29989885  0.19996652]]\n"
     ]
    }
   ],
   "source": [
    "train(inputs, targets)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
